---
title: "Getting started with EM-MIL"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{getting-started}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  fig.width = 7, 
  warning = FALSE
)
```

```{r setup}
library(emmil)
library(ggplot2)
```

```{r}
#parameters 
rho <- 0.5
zeta <- 0.5
lambda <- 0.1
num_iterations <- 100
```


# Simulate data


```{r}
simulated_data <- 
  emmil_simulate_data(
    num_cells = 100, 
    num_features = 10, 
    rho = rho, 
    zeta = zeta, 
    shift = 4
  )

X <- simulated_data$X
z <- simulated_data$z
true_y <- simulated_data$true_y
```

# Calculate case-control intercept adjustment


```{r}
# From Erin: ------ 
# Here we address our sampling bias.
# This should be pretty close to 0, because we don't have any sampling bias!
# Including for completeness.
# -------------------------
# Question from Tim: Can we estimate rho and zeta (but especially zeta) from the training data? 
# I guess that kind of defeats the point of using an adjustment in the first place. 
case_control_intercept_adjustment <- 
  emmil_calculate_case_control_adjustment(
    z = z, 
    rho = rho, 
    zeta = zeta
  )

print(round(case_control_intercept_adjustment, 4))
```



# Fit model

## glmnet

```{r}
glmnet_result <- 
  emmil_fit_glmnet(
    X = X, 
    z = z, 
    rho = rho, 
    zeta = zeta, 
    lambda = lambda, 
    case_control_adjustment = case_control_intercept_adjustment, 
    num_iterations = num_iterations
  )

lls <- emmil_get_log_likelihoods(glmnet_result)
y <- 
  predict(
    glmnet_result, 
    newx = X, 
    s = emmil_get_hyperparameters(glmnet_result)$lambda, 
    type = "response"
  )
glmnet_model <- glmnet_result

```

```{r}
lls |> 
  emmil_plot_lls()

glmnet_predictions <- 
  glmnet_model |> 
  predict(newx = X, adjust = FALSE, s = lambda, type = "response") |> 
  as.numeric()

glmnet_performance_tibble <- 
  tibble::tibble(
  glmnet_predictions = glmnet_predictions, 
  truth = dplyr::if_else(true_y == 0, "healthy", "disease"), 
  z = z, 
  sample_type = dplyr::if_else(z == 0, "healthy sample", "disease sample")
) 

glmnet_performance_tibble |> 
  ggplot(aes(y = glmnet_predictions, x = truth, fill = sample_type)) + 
  geom_boxplot(position = position_dodge(preserve = "single")) + 
  scale_x_discrete(drop = FALSE) + 
  scale_y_continuous(limits = c(0, 1)) + 
  scale_color_discrete(drop = FALSE) + 
  theme_bw() + 
  labs(subtitle = "glmnet performance", x = "true label", y = "predicted probability")
```

## mlp

What if instead of using a glmnet model, we used a multilayer perceptron? 

```{r}
mlp_result <- 
  emmil_fit_mlp(
    X = X, 
    z = z, 
    rho = rho, 
    zeta = zeta, 
    num_iterations = num_iterations, 
    num_neurons = 5, 
    decay = 0.4, 
    maxit = 100
  )

lls <- mlp_result |> 
  emmil_get_log_likelihoods()

y <- 
  mlp_result |> 
  predict(newdata = X, type = "raw")

mlp_model <- mlp_result

```


```{r}
# This should be increasing:
lls |> 
  emmil_plot_lls()

# This should differentiate between the groups.
# Let's only look at the instances where z == 1.
# (We know the labels when z == 0.)
mlp_predictions <- 
  mlp_model |> 
  predict(newdata = as.data.frame(X), adjust = FALSE, type = "raw") |> 
  as.numeric()

mlp_performance_tibble <- 
  tibble::tibble(
    mlp_predictions = mlp_predictions, 
    truth = dplyr::if_else(true_y == 0, "healthy", "disease"), 
    z = z, 
    sample_type = dplyr::if_else(z == 0, "healthy sample", "cancer sample")
  ) 


mlp_performance_tibble |> 
  ggplot(aes(y = mlp_predictions, x = truth, fill = sample_type)) + 
  geom_boxplot(position = position_dodge(preserve = "single")) + 
  scale_x_discrete(drop = FALSE) + 
  scale_color_discrete(drop = FALSE) + 
  scale_y_continuous(limits = c(0, 1)) + 
  theme_bw() + 
  labs(subtitle = "MLP performance", x = "true label", y = "predicted probability")
```



## pseudobinomial (pseudo-logistic regression)

What if instead of using either of the two previous models, we used logistic regression (using a pseudobinomial fit to accommodate the soft labels)?

```{r, warning = FALSE}
glm_result <- 
  emmil_fit_glm(
    X = X, 
    z = z, 
    rho = rho, 
    zeta = zeta, 
    num_iterations = num_iterations
  )

lls <- 
  glm_result |> 
  emmil_get_log_likelihoods()
y <- 
  glm_result |> 
  predict(newdata = as.data.frame(X), adjust = FALSE, type = "response")
glm_model <- glm_result

```



```{r}
lls |> 
  emmil_plot_lls() + 
  labs(subtitle = "logistic regression log-likelihood results")

glm_predictions <- 
  glm_model |> 
  predict(newdata = as.data.frame(X), type = "response")


glm_performance_tibble <- 
  tibble::tibble(
    glm_predictions = glm_predictions, 
    truth = dplyr::if_else(true_y == 0, "healthy", "disease"), 
    z = z, 
    sample_type = dplyr::if_else(z == 0, "healthy sample", "cancer sample")
  ) 

glm_performance_tibble |> 
  ggplot(aes(y = glm_predictions, x = truth, fill = sample_type)) + 
  geom_boxplot(position = position_dodge(preserve = "single")) + 
  scale_x_discrete(drop = FALSE) + 
  scale_color_discrete(drop = FALSE) + 
  theme_bw() + 
  labs(subtitle = "Logistic regression performance", x = "true label", y = "predicted probability")
```

## nnet via tidymodels

What if we tried to integrate EM-MIL with the [tidymodels](https://www.tidymodels.org/) ecosystem of models? (Here, we fit an MLP again, but we do it the tidymodels way). 

```{r}
nnet_spec <- 
  parsnip::mlp(
    engine = "nnet", 
    mode = "regression", 
    hidden_units = 5, 
    penalty = 0.4, 
    epochs = 10,
  )

tidymodel_result <- 
  emmil_fit_tidymodels(
    X = X, 
    z = z, 
    rho = rho, 
    zeta = zeta, 
    num_iterations = num_iterations, 
    model_spec = nnet_spec
  )

lls <- 
  tidymodel_result |> 
  emmil_get_log_likelihoods()
y <- 
  tidymodel_result |> 
  predict(new_data = as.data.frame(X))
y <- y$.pred

tidymodel_model <- tidymodel_result

```


```{r}
lls |> 
  emmil_plot_lls() + 
  labs(subtitle = "tidymodels nnet log-likelihood results")

tidymodel_predictions <- 
  tidymodel_model |> 
  predict(new_data = as.data.frame(X), type = "raw") |> 
  pmin(1) |> 
  pmax(0)


tidymodel_performance_tibble <- 
  tibble::tibble(
    tidymodel_predictions = tidymodel_predictions, 
    truth = dplyr::if_else(true_y == 0, "healthy", "disease"), 
    z = z, 
    sample_type = dplyr::if_else(z == 0, "healthy sample", "cancer sample")
  ) 

tidymodel_performance_tibble |> 
  ggplot(aes(y = tidymodel_predictions, x = truth, fill = sample_type)) + 
  geom_boxplot(position = position_dodge(preserve = "single")) + 
  scale_color_discrete(drop = FALSE) + 
  theme_bw() + 
  labs(subtitle = "Tidymodels nnet performance", x = "true label", y = "predicted probability")
```


At the moment, the log-likelihood calculation seems buggy here. All signs point to how tidymodels handles classification vs. regression (which can be fixed). 



# Compare models

We can compare all the models we've fit so far. 

```{r}
model_plot <- 
  glmnet_performance_tibble |> 
  dplyr::mutate(
    glm_predictions = glm_performance_tibble$glm_predictions, 
    mlp_predictions = mlp_performance_tibble$mlp_predictions, 
    tidymodel_predictions = tidymodel_performance_tibble$tidymodel_predictions
  ) |> 
  tidyr::pivot_longer(
    cols = ends_with("_predictions"), 
    names_to = "model", 
    values_to = "prediction"
  ) |> 
  dplyr::mutate(
    model = 
      stringr::str_remove(model, "_predictions") |> 
      factor(levels = c("glmnet", "glm", "mlp", "tidymodel")) |> 
      forcats::fct_recode(`tidymodel mlp` = "tidymodel")
  ) |> 
  dplyr::filter(model != "tidymodel mlp") |> 
  ggplot(aes(x = sample_type, y = prediction, fill = truth)) +
  geom_boxplot(position = position_dodge(preserve = "single")) + 
  scale_color_discrete(drop = FALSE) + 
  facet_grid(cols = vars(model)) + 
  theme_bw() + 
  labs(
    y = "EMMIL prediction", 
    fill = "True cell-level label", 
    x = "Sample type"
  )

print(model_plot)

```


```{r}
scatterplot<- 
  glmnet_performance_tibble |> 
  dplyr::mutate(
    glm_predictions = glm_performance_tibble$glm_predictions, 
    mlp_predictions = mlp_performance_tibble$mlp_predictions, 
    tidymodel_predictions = tidymodel_performance_tibble$tidymodel_predictions
  ) |> 
  dplyr::bind_cols(
    dplyr::as_tibble(X)
  ) |> 
  tidytof::tof_reduce_dimensions(
    pca_cols = starts_with("V"), 
    method = "pca"
  ) |> 
  ggplot(aes(x = .pc1, y = .pc2, color = sample_type, shape = truth)) + 
  geom_point(size = 3) + 
  ggthemes::scale_color_tableau() + 
  theme_bw() + 
  labs(
    shape = "True cell-level label", 
    color = "Sample type"
  )

print(scatterplot)
```




```{r}
coef(glmnet_model, s = emmil_get_hyperparameters(glmnet_model)$lambda) |> 
  as.matrix() |> 
  dplyr::as_tibble(rownames = "feature") |> 
  dplyr::transmute(
    coefficient = s1, 
    feature = forcats::fct_reorder(feature, abs(coefficient)), 
    sign = as.character(sign(coefficient))
  ) |> 
  dplyr::filter(abs(coefficient) > 0) |> 
  ggplot(aes(x = abs(coefficient), y = feature, fill = sign)) + 
  geom_col() + 
  theme_bw()
```






